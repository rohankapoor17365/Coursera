{"cells":[{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-09-16T05:41:07.049582Z","iopub.status.busy":"2023-09-16T05:41:07.049310Z","iopub.status.idle":"2023-09-16T05:41:37.009255Z","shell.execute_reply":"2023-09-16T05:41:37.008116Z","shell.execute_reply.started":"2023-09-16T05:41:07.049551Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting torch-geometric\n","  Using cached torch_geometric-2.3.1-py3-none-any.whl\n","Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["ERROR: Could not find a version that satisfies the requirement cv2 (from versions: none)\n","ERROR: No matching distribution found for cv2\n"]}],"source":["pip install torch-geometric"]},{"cell_type":"code","execution_count":6,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-09-16T05:41:37.012076Z","iopub.status.busy":"2023-09-16T05:41:37.011715Z","iopub.status.idle":"2023-09-16T05:41:43.154214Z","shell.execute_reply":"2023-09-16T05:41:43.150666Z","shell.execute_reply.started":"2023-09-16T05:41:37.012043Z"},"trusted":true},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'cv2'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[1;32mc:\\Users\\NandiniSharma\\Downloads\\cnn-cd.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/NandiniSharma/Downloads/cnn-cd.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/NandiniSharma/Downloads/cnn-cd.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/NandiniSharma/Downloads/cnn-cd.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"]}],"source":["import cv2\n","import os\n","import numpy as np\n","import pandas as pd\n","from glob import glob\n","from PIL import Image\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from skimage.io import imread\n","\n","# Pytorch Libraries\n","import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch_geometric.nn import GCNConv, BatchNorm\n","import torch_geometric.transforms as T\n","import torch_geometric\n","\n","from torch.optim import lr_scheduler\n","from torchvision import models, transforms\n","from torchvision.datasets import ImageFolder\n","from torch.utils.data import TensorDataset, DataLoader, Dataset\n","\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.calibration import CalibratedClassifierCV\n","from sklearn.ensemble import BaggingClassifier\n","from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score\n","from sklearn.metrics import classification_report, roc_curve, roc_auc_score, confusion_matrix, precision_recall_curve, auc\n","# from sklearn.metrics import plot_roc_curve, plot_confusion_matrix\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import f1_score\n","from sklearn.svm import SVC\n","\n","sns.set()"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.status.busy":"2023-09-16T05:41:43.155224Z","iopub.status.idle":"2023-09-16T05:41:43.155567Z","shell.execute_reply":"2023-09-16T05:41:43.155418Z","shell.execute_reply.started":"2023-09-16T05:41:43.155402Z"},"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'pd' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32mc:\\Users\\NandiniSharma\\Downloads\\cnn-cd.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/NandiniSharma/Downloads/cnn-cd.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m meta_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39m/kaggle/input/histopathologic-cancer-detection/train_labels.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/NandiniSharma/Downloads/cnn-cd.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m meta_data \u001b[39m=\u001b[39m meta_data\u001b[39m.\u001b[39mgroupby(\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m, group_keys\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39msample(\u001b[39m2500\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/NandiniSharma/Downloads/cnn-cd.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m meta_data\u001b[39m.\u001b[39mreset_index(drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n","\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"]}],"source":["meta_data = pd.read_csv('/kaggle/input/histopathologic-cancer-detection/train_labels.csv')\n","meta_data = meta_data.groupby('label', group_keys=False).apply(lambda x: x.sample(2500))\n","meta_data.reset_index(drop=True, inplace=True)\n","meta_data.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-09-16T05:41:43.156976Z","iopub.status.idle":"2023-09-16T05:41:43.157874Z","shell.execute_reply":"2023-09-16T05:41:43.157643Z","shell.execute_reply.started":"2023-09-16T05:41:43.157619Z"},"trusted":true},"outputs":[],"source":["meta_data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-09-16T05:41:43.159250Z","iopub.status.idle":"2023-09-16T05:41:43.160212Z","shell.execute_reply":"2023-09-16T05:41:43.159984Z","shell.execute_reply.started":"2023-09-16T05:41:43.159960Z"},"trusted":true},"outputs":[],"source":["base_dir = os.path.join('..', 'input/histopathologic-cancer-detection/train')\n","\n","imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x \n","                     for x in glob(os.path.join(base_dir,'*.tif'))}\n","\n","meta_data['path'] = meta_data['id'].map(imageid_path_dict.get)\n","meta_data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-09-16T05:41:43.161457Z","iopub.status.idle":"2023-09-16T05:41:43.162682Z","shell.execute_reply":"2023-09-16T05:41:43.162338Z","shell.execute_reply.started":"2023-09-16T05:41:43.162315Z"},"trusted":true},"outputs":[],"source":["n_samples = 6\n","n_classes = len(meta_data['label'].unique())\n","df = meta_data.sort_values(['label']).groupby('label')\n","fig, axs = plt.subplots(n_classes, n_samples, figsize = (10, 4))\n","for ax, (type_, rows) in zip(axs, df):\n","    ax[0].set_title('Class: '+ str(type_), fontsize=15)\n","    for sub_ax, (_, subset) in zip(ax, rows.sample(n_samples).iterrows()):\n","        img = imread(subset['path'])\n","        sub_ax.imshow(img)\n","        sub_ax.axis('off')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-09-16T05:41:43.163904Z","iopub.status.idle":"2023-09-16T05:41:43.164854Z","shell.execute_reply":"2023-09-16T05:41:43.164618Z","shell.execute_reply.started":"2023-09-16T05:41:43.164594Z"},"trusted":true},"outputs":[],"source":["data = []\n","outliers = []\n","for path in meta_data['path']:\n","    img = cv2.imread(path)\n","        \n","    avgR = np.mean(img[:,:,2])\n","    avgG = np.mean(img[:,:,1])\n","    avgB = np.mean(img[:,:,0])\n","    RGB = np.mean([avgR, avgG, avgB])\n","    \n","    data.append([avgR, avgG, avgB, RGB])\n","    \n","    if ((RGB <= 45) or (RGB >= 245)) : outliers.append(meta_data.loc[meta_data['path'] == path].index[0])\n","    \n","rgb = pd.DataFrame(data, columns=['Red Channel Mean','Green Channel Mean','Blue Channel Mean', 'RGB Mean'])\n","\n","meta_data = pd.concat([meta_data.reset_index(drop=True), rgb], axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-09-16T05:41:43.166103Z","iopub.status.idle":"2023-09-16T05:41:43.166924Z","shell.execute_reply":"2023-09-16T05:41:43.166691Z","shell.execute_reply.started":"2023-09-16T05:41:43.166668Z"},"trusted":true},"outputs":[],"source":["g = sns.pairplot(meta_data[['Red Channel Mean', 'Green Channel Mean', 'Blue Channel Mean', 'RGB Mean', 'label']],\n","             hue='label', plot_kws = {'alpha': 0.3})\n","\n","g.fig.set_size_inches(12,8)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-09-16T05:41:43.168250Z","iopub.status.idle":"2023-09-16T05:41:43.169038Z","shell.execute_reply":"2023-09-16T05:41:43.168817Z","shell.execute_reply.started":"2023-09-16T05:41:43.168795Z"},"trusted":true},"outputs":[],"source":["len(outliers)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-09-16T05:41:43.170392Z","iopub.status.idle":"2023-09-16T05:41:43.171361Z","shell.execute_reply":"2023-09-16T05:41:43.171142Z","shell.execute_reply.started":"2023-09-16T05:41:43.171119Z"},"trusted":true},"outputs":[],"source":["extremely_low_pxl_img = meta_data[meta_data['RGB Mean'] <= 45]\n","extremely_high_pxl_img = meta_data[meta_data['RGB Mean'] >= 245]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-09-16T05:41:43.172820Z","iopub.status.idle":"2023-09-16T05:41:43.173761Z","shell.execute_reply":"2023-09-16T05:41:43.173519Z","shell.execute_reply.started":"2023-09-16T05:41:43.173492Z"},"trusted":true},"outputs":[],"source":["n_samples = 5\n","df = extremely_high_pxl_img.sort_values(['label']).groupby('label')\n","fig, axs = plt.subplots(2, n_samples, figsize = (10, 4))\n","for ax, (type_, rows) in zip(axs, df):\n","    ax[0].set_title('Class: '+ str(type_), fontsize=15)\n","    for sub_ax, (_, subset) in zip(ax, rows.sample(n_samples, replace = True).iterrows()):\n","        img = imread(subset['path'])\n","        sub_ax.imshow(img)\n","        sub_ax.axis('off')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-09-16T05:41:43.174993Z","iopub.status.idle":"2023-09-16T05:41:43.175583Z","shell.execute_reply":"2023-09-16T05:41:43.175371Z","shell.execute_reply.started":"2023-09-16T05:41:43.175349Z"},"trusted":true},"outputs":[],"source":["n_samples = 5\n","df = extremely_low_pxl_img.sort_values(['label']).groupby('label')\n","fig, axs = plt.subplots(2, n_samples, figsize = (10, 4))\n","for ax, (type_, rows) in zip(axs, df):\n","    ax[0].set_title('Class: '+ str(type_), fontsize=15)\n","    for sub_ax, (_, subset) in zip(ax, rows.sample(n_samples, replace = True).iterrows()):\n","        img = imread(subset['path'])\n","        sub_ax.imshow(img)\n","        sub_ax.axis('off')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-09-16T05:41:43.177147Z","iopub.status.idle":"2023-09-16T05:41:43.178098Z","shell.execute_reply":"2023-09-16T05:41:43.177866Z","shell.execute_reply.started":"2023-09-16T05:41:43.177838Z"},"trusted":true},"outputs":[],"source":["meta_data = meta_data.drop(outliers)\n","meta_data['label'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-09-16T05:41:43.180294Z","iopub.status.idle":"2023-09-16T05:41:43.181380Z","shell.execute_reply":"2023-09-16T05:41:43.181160Z","shell.execute_reply.started":"2023-09-16T05:41:43.181137Z"},"trusted":true},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(self, data_df, transform=None):\n","        self.data_df = data_df\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.data_df)\n","\n","    def __getitem__(self, index):\n","        img_path = self.data_df.iloc[index]['path']\n","        label = self.data_df.iloc[index]['label']\n","        \n","        # Load image from file\n","        img = Image.open(img_path).convert('RGB')\n","        \n","        if self.transform is not None:\n","            img = self.transform(img)\n","        \n","        return img, label\n","\n","# Split data into train and test sets\n","train_df, test_df = train_test_split(meta_data, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-09-16T05:41:43.182803Z","iopub.status.idle":"2023-09-16T05:41:43.183724Z","shell.execute_reply":"2023-09-16T05:41:43.183500Z","shell.execute_reply.started":"2023-09-16T05:41:43.183472Z"},"trusted":true},"outputs":[],"source":["# Define the batch size\n","batch_size = 32"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-09-16T05:41:43.185135Z","iopub.status.idle":"2023-09-16T05:41:43.185606Z","shell.execute_reply":"2023-09-16T05:41:43.185380Z","shell.execute_reply.started":"2023-09-16T05:41:43.185359Z"},"trusted":true},"outputs":[],"source":["# Define the data transforms for training and testing datasets\n","train_transforms = transforms.Compose([\n","    transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n","    transforms.RandomRotation(degrees=15),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.CenterCrop(size=224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                         std=[0.229, 0.224, 0.225])\n","])\n","\n","test_transforms = transforms.Compose([\n","    transforms.Resize(size=256),\n","    transforms.CenterCrop(size=224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                         std=[0.229, 0.224, 0.225])\n","])\n","\n","# Load the data\n","train_dataset = CustomDataset(train_df, transform=train_transforms)\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n","test_dataset = CustomDataset(test_df, transform=test_transforms)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-09-16T05:41:43.187250Z","iopub.status.idle":"2023-09-16T05:41:43.187719Z","shell.execute_reply":"2023-09-16T05:41:43.187495Z","shell.execute_reply.started":"2023-09-16T05:41:43.187473Z"},"trusted":true},"outputs":[],"source":["def evaluate1(model, loader, criterion):\n","    correct = 0\n","    total = 0\n","    total_loss = 0\n","    \n","    model.eval()\n","    with torch.no_grad():\n","        for data in loader:\n","            images, labels = data\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            outputs = model(images)\n","            loss = criterion(outputs.squeeze(), labels.float())\n","            total_loss += loss.item()\n","            predicted = torch.round(torch.sigmoid(outputs))\n","            total += labels.size(0)\n","            correct += (predicted == labels.unsqueeze(1)).sum().item()\n","\n","    acc = correct / total\n","    avg_loss = total_loss / len(loader)\n","    model.train()\n","    return acc, avg_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-09-16T05:41:43.189414Z","iopub.status.idle":"2023-09-16T05:41:43.189904Z","shell.execute_reply":"2023-09-16T05:41:43.189671Z","shell.execute_reply.started":"2023-09-16T05:41:43.189650Z"},"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# define hyperparameters\n","learning_rate = 0.001\n","num_epochs = 20\n","roc_aucs = []\n","\n","# define binary cross entropy loss\n","criterion = nn.BCEWithLogitsLoss()\n","\n","# define ResNet50, VGG19, Inception, and DenseNet121 models\n","models_dict = {'ResNet50': models.resnet50(weights='DEFAULT'),\n","               'VGG19': models.vgg19(weights='DEFAULT'),\n","              'VGG16': models.vgg16(weights='DEFAULT'),\n","              'DenseNet121': models.densenet121(weights='DEFAULT')}\n","\n","# define empty lists to store accuracy and loss\n","accs = []\n","losses = []\n","\n","# loop over models\n","for model_name, model in models_dict.items():\n","    \n","    print('Training', model_name, 'model')\n","    \n","    if (model_name == 'VGG19') | (model_name == 'VGG16'):\n","        num_features = model.classifier[-1].in_features\n","        model.classifier[-1] = nn.Linear(num_features, 512)\n","        model.classifier.add_module('bn1', nn.BatchNorm1d(512))\n","        model.classifier.add_module('relu1', nn.ReLU(inplace=True))\n","        model.classifier.add_module('dropout1', nn.Dropout())\n","        model.classifier.add_module('fc2', nn.Linear(512, 256))\n","        model.classifier.add_module('bn2', nn.BatchNorm1d(256))\n","        model.classifier.add_module('relu2', nn.ReLU(inplace=True))\n","        model.classifier.add_module('dropout2', nn.Dropout())\n","        model.classifier.add_module('fc3', nn.Linear(256, 1))\n","    else:\n","        if model_name == 'DenseNet121':\n","            num_ftrs = model.classifier.in_features\n","            model.classifier = nn.Sequential(\n","                nn.Linear(num_ftrs, 512),\n","                nn.BatchNorm1d(512),\n","                nn.ReLU(inplace=True),\n","                nn.Dropout(),\n","                nn.Linear(512, 256),\n","                nn.BatchNorm1d(256),\n","                nn.ReLU(inplace=True),\n","                nn.Dropout(),\n","                nn.Linear(256, 1)\n","            )\n","        else:\n","            num_ftrs = model.fc.in_features\n","            model.fc = nn.Sequential(\n","                nn.Linear(num_ftrs, 512),\n","                nn.BatchNorm1d(512),\n","                nn.ReLU(inplace=True),\n","                nn.Dropout(),\n","                nn.Linear(512, 256),\n","                nn.BatchNorm1d(256),\n","                nn.ReLU(inplace=True),\n","                nn.Dropout(),\n","                nn.Linear(256, 1)\n","            )\n","\n","    model.to(device)\n","    \n","    # define optimizer\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n","    \n","    # define empty lists to store predictions and labels\n","    y_preds = []\n","    y_trues = []\n","    # train the model\n","    for epoch in range(num_epochs):\n","        \n","        running_loss = 0.0\n","        total = 0\n","        correct = 0\n","        \n","        for i, (inputs, labels) in enumerate(train_loader):\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            \n","            # zero the parameter gradients\n","            optimizer.zero_grad()\n","\n","            # forward + backward + optimize\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels.float().unsqueeze(1))\n","            loss.backward()\n","            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","            optimizer.step()\n","\n","            # calculate accuracy\n","            total += labels.size(0)\n","            predicted = torch.round(torch.sigmoid(outputs))\n","            correct += (predicted == labels.unsqueeze(1)).sum().item()\n","            acc = correct / total\n","\n","            # append accuracy and loss to the lists\n","            accs.append(acc)\n","            losses.append(loss.item())\n","\n","            # append predictions and labels to the lists\n","            y_preds += predicted.cpu().detach().numpy().tolist()\n","            y_trues += labels.cpu().detach().numpy().tolist()\n","\n","        print('Epoch [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n","              .format(epoch+1, num_epochs, loss.item(), acc*100))\n","        \n","        # calculate validation accuracy and loss\n","        val_acc, val_loss = evaluate1(model, test_loader, criterion)\n","        print('Accuracy of the network on the validation set: %d %%' % (100 * val_acc))\n","\n","        # adjust learning rate based on validation loss\n","        scheduler.step(val_loss)\n","        \n","    torch.save(model.state_dict(), model_name + '.pt')\n","\n","# Plot AUC ROC Curve\n","fig, axs = plt.subplots(2, 2, figsize=(10, 8))\n","axs = axs.ravel()\n","for i, (name, model) in enumerate(models_dict.items()):\n","    model.eval()\n","    y_score = []\n","    y_true = []\n","    with torch.no_grad():\n","        for inputs, labels in test_loader:\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","            model = model.to(device)\n","            outputs = model(inputs)\n","            outputs = torch.sigmoid(outputs)\n","            y_score.extend(outputs.cpu().numpy()[:, 0])\n","            y_true.extend(labels.cpu().numpy())\n","\n","    fpr, tpr, _ = roc_curve(y_true, y_score)\n","    roc_auc = auc(fpr, tpr)\n","\n","    axs[i].plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.2f})')\n","    axs[i].plot([0, 1], [0, 1], 'k--')\n","    axs[i].set_xlabel('False Positive Rate')\n","    axs[i].set_ylabel('True Positive Rate')\n","    axs[i].set_title(name)\n","    axs[i].legend(loc=\"lower right\")\n","    plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-09-16T05:41:43.191293Z","iopub.status.idle":"2023-09-16T05:41:43.192096Z","shell.execute_reply":"2023-09-16T05:41:43.191874Z","shell.execute_reply.started":"2023-09-16T05:41:43.191851Z"},"trusted":true},"outputs":[],"source":["# Plot Confusion Matrix\n","fig, axs = plt.subplots(2, 2, figsize=(10, 8))\n","axs = axs.ravel()\n","\n","# Loop through each model and plot its confusion matrix in a subplot\n","for i, (name, model) in enumerate(models_dict.items()):\n","    model.eval()\n","    y_pred = []\n","    y_true = []\n","    threshold = 0.5\n","    with torch.no_grad():\n","        for inputs, labels in test_loader:\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","            model = model.to(device)\n","            outputs = model(inputs)\n","            outputs = torch.sigmoid(outputs)\n","            output_numpy = outputs.cpu().numpy()\n","            lab = (output_numpy >= threshold).astype(int)\n","            y_pred.extend(lab.tolist())\n","            y_true.extend(labels.cpu().numpy())\n","            \n","    y_pred = list(np.array(y_pred).flat)\n","    ax = axs[i]\n","    cm = confusion_matrix(y_true, y_pred)\n","    sns.heatmap(cm, annot=True, cmap=\"Blues\", ax=ax, fmt=\"g\")\n","    ax.set_title(\"Confusion Matrix - {}\".format(name))\n","    ax.set_xlabel(\"Predicted Labels\")\n","    ax.set_ylabel(\"True Labels\")\n","\n","# Adjust spacing between subplots\n","plt.subplots_adjust(hspace=0.3, wspace=0.3)\n","\n","# Show the plot\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Ensemble Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-09-16T05:41:43.193707Z","iopub.status.idle":"2023-09-16T05:41:43.194179Z","shell.execute_reply":"2023-09-16T05:41:43.193971Z","shell.execute_reply.started":"2023-09-16T05:41:43.193949Z"},"trusted":true},"outputs":[],"source":["def evaluate(model, loader, criterion):\n","    correct = 0\n","    total = 0\n","    total_loss = 0\n","    \n","    model.eval()\n","    with torch.no_grad():\n","        for data in loader:\n","            images, labels = data\n","            images = images.to(device)\n","            labels = labels.to(device)\n","            outputs = model(images)\n","            loss = criterion(outputs.squeeze(), labels.float())\n","            total_loss += loss.item()\n","            predicted = torch.round(outputs) # round the outputs to 0 or 1\n","            total += labels.size(0)\n","            correct += (predicted == labels.unsqueeze(1)).sum().item()\n","\n","    acc = correct / total\n","    avg_loss = total_loss / len(loader)\n","    model.train()\n","    return acc, avg_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-09-16T05:41:43.195620Z","iopub.status.idle":"2023-09-16T05:41:43.196498Z","shell.execute_reply":"2023-09-16T05:41:43.196272Z","shell.execute_reply.started":"2023-09-16T05:41:43.196244Z"},"trusted":true},"outputs":[],"source":["class Ensemble(nn.Module):\n","    def __init__(self, models_dict):\n","        super(Ensemble, self).__init__()\n","        self.models_dict = models_dict\n","        \n","    def forward(self, x):\n","        count = 0\n","        predicted = 0\n","        for model_name, model in self.models_dict.items():\n","            if model_name == 'VGG19':\n","                count += 0.225*torch.sigmoid(model(x))\n","            if model_name == 'VGG16':\n","                count += 0.225*torch.sigmoid(model(x))\n","            if model_name == 'ResNet50':\n","                count += 0.275*torch.sigmoid(model(x))\n","            if model_name == 'DenseNet121':\n","                count += 0.275*torch.sigmoid(model(x))\n","\n","        return torch.tensor(count, dtype=torch.float32)\n","        \n","    \n","ensemble = Ensemble(models_dict)\n","\n","ensemble.to(device)\n","\n","val_acc, val_loss = evaluate(ensemble, test_loader, criterion)\n","print('Accuracy of the ensemble on the validation set: %d %%' % (100 * val_acc))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-09-16T05:41:43.198555Z","iopub.status.idle":"2023-09-16T05:41:43.199362Z","shell.execute_reply":"2023-09-16T05:41:43.199146Z","shell.execute_reply.started":"2023-09-16T05:41:43.199124Z"},"trusted":true},"outputs":[],"source":["# Evaluate the model on the test set\n","y_test_preds = []\n","y_test_trues = []\n","predlist = []\n","\n","ensemble.eval()\n","\n","with torch.no_grad():\n","    for data in test_loader:\n","        images, labels = data\n","        images, labels = images.to(device), labels.to(device)\n","        outputs = ensemble(images)\n","        predicted = torch.round(outputs)\n","        predlist += predicted.cpu().detach().numpy().tolist()\n","        outputs = torch.sigmoid(outputs)\n","        y_test_preds += outputs.cpu().detach().numpy().tolist()\n","        y_test_trues += labels.cpu().detach().numpy().tolist()\n","\n","       \n","\n","# Calculate AUC ROC score\n","auc_roc_score = roc_auc_score(y_test_trues, y_test_preds)\n","\n","# Plot ROC curve\n","fpr, tpr, _ = roc_curve(y_test_trues, y_test_preds)\n","\n","plt.plot(fpr, tpr, label=f'ROC curve (AUC =%.2f)' % auc_roc_score)\n","plt.plot([0, 1], [0, 1], 'k--')\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Receiver Operating Characteristic')\n","plt.legend(loc=\"lower right\")\n","plt.show()\n","\n","# Calculate confusion matrix\n","confusion_mat = confusion_matrix(y_test_trues, predlist)\n","\n","# Plot confusion matrix\n","labels = ['Negative', 'Positive']\n","plt.figure(figsize=(5,5))\n","sns.heatmap(confusion_mat, xticklabels=labels, yticklabels=labels, annot=True, fmt='d', cmap='Blues')\n","plt.title('Confusion Matrix')\n","plt.xlabel('Predicted Label')\n","plt.ylabel('True Label')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Custom Binary Classification CNN Model"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2023-09-16T05:41:43.200796Z","iopub.status.idle":"2023-09-16T05:41:43.201385Z","shell.execute_reply":"2023-09-16T05:41:43.201171Z","shell.execute_reply.started":"2023-09-16T05:41:43.201149Z"},"trusted":true},"outputs":[],"source":["class BinaryCNN(nn.Module):\n","    def __init__(self):\n","        super(BinaryCNN, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n","        self.bn1 = nn.BatchNorm2d(32)\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n","        self.bn2 = nn.BatchNorm2d(64)\n","        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n","        self.bn3 = nn.BatchNorm2d(128)\n","        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n","        self.bn4 = nn.BatchNorm2d(256)\n","        self.fc1 = nn.Linear(256 * 6 * 6, 512)\n","        self.bn5 = nn.BatchNorm1d(512)\n","        self.dropout = nn.Dropout(p=0.5)\n","        self.fc2 = nn.Linear(512, 1)\n","        self.sigmoid = nn.Sigmoid()\n","        \n","    def forward(self, x):\n","        x = self.pool(nn.functional.relu(self.bn1(self.conv1(x))))\n","        x = self.pool(nn.functional.relu(self.bn2(self.conv2(x))))\n","        x = self.pool(nn.functional.relu(self.bn3(self.conv3(x))))\n","        x = self.pool(nn.functional.relu(self.bn4(self.conv4(x))))\n","        x = x.view(-1, 256 * 6 * 6)\n","        x = nn.functional.relu(self.bn5(self.fc1(x)))\n","        x = self.dropout(x)\n","        x = self.fc2(x)\n","        x = self.sigmoid(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-09-16T05:41:43.203680Z","iopub.status.idle":"2023-09-16T05:41:43.204451Z","shell.execute_reply":"2023-09-16T05:41:43.204229Z","shell.execute_reply.started":"2023-09-16T05:41:43.204206Z"},"trusted":true},"outputs":[],"source":["# Set the hyperparameters\n","batch_size = 32\n","\n","train_transforms = transforms.Compose([\n","    transforms.RandomResizedCrop(size=256),\n","    transforms.RandomRotation(degrees=15),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.CenterCrop(size=96),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                         std=[0.229, 0.224, 0.225])\n","])\n","\n","test_transforms = transforms.Compose([\n","    transforms.Resize(size=256),\n","    transforms.CenterCrop(size=96),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                         std=[0.229, 0.224, 0.225])\n","])\n","\n","\n","# Create the datasets and data loaders\n","dataset_train = CustomDataset(train_df, transform=train_transforms)\n","dataset_valid = CustomDataset(test_df, transform=test_transforms)\n","loader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n","loader_valid = DataLoader(dataset_valid, batch_size=batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-09-16T05:41:43.205842Z","iopub.status.idle":"2023-09-16T05:41:43.206615Z","shell.execute_reply":"2023-09-16T05:41:43.206383Z","shell.execute_reply.started":"2023-09-16T05:41:43.206360Z"},"trusted":true},"outputs":[],"source":["learning_rate = 0.005\n","\n","# Initialize the model, criterion, and optimizer\n","model = BinaryCNN()\n","criterion = nn.BCELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-09-16T05:41:43.208037Z","iopub.status.idle":"2023-09-16T05:41:43.208875Z","shell.execute_reply":"2023-09-16T05:41:43.208624Z","shell.execute_reply.started":"2023-09-16T05:41:43.208583Z"},"trusted":true},"outputs":[],"source":["# Train the model\n","accs = []\n","losses = []\n","y_preds = []\n","y_trues = []\n","count = 0\n","num_epochs = 20\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","for epoch in range(num_epochs):\n","    running_loss = 0.0\n","    total = 0\n","    correct = 0\n","    for i, data in enumerate(loader_train, 0):\n","        inputs, labels = data\n","        inputs, labels = inputs.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","        \n","        outputs = model(inputs)\n","        loss = criterion(outputs.squeeze(), labels.float())\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","        if i % 100 == 99:\n","            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 100))\n","            running_loss = 0.0\n","                \n","        # calculate accuracy\n","        total += labels.size(0)\n","        predicted = torch.round(outputs)\n","        correct += (predicted == labels.unsqueeze(1)).sum().item()\n","        acc = correct / total\n","\n","        # append accuracy and loss to the lists\n","        accs.append(acc)\n","        losses.append(loss.item())\n","\n","        # append predictions and labels to the lists\n","        y_preds += predicted.cpu().detach().numpy().tolist()\n","        y_trues += labels.cpu().detach().numpy().tolist()\n","        \n","    print('Epoch [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n","              .format(epoch+1, num_epochs, loss.item(), acc*100))\n","    \n","    # calculate validation accuracy and loss\n","    val_acc, val_loss = evaluate(model, loader_valid, criterion)\n","    print('Accuracy of the network on the validation set: %d %%' % (100 * val_acc))\n","    \n","    scheduler.step(val_loss)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-09-16T05:41:43.210313Z","iopub.status.idle":"2023-09-16T05:41:43.211129Z","shell.execute_reply":"2023-09-16T05:41:43.210901Z","shell.execute_reply.started":"2023-09-16T05:41:43.210877Z"},"trusted":true},"outputs":[],"source":["y_test_preds = []\n","y_test_trues = []\n","predlist = []\n","model.eval()\n","with torch.no_grad():\n","    for data in loader_valid:\n","        images, labels = data\n","        images, labels = images.to(device), labels.to(device)\n","        outputs = model(images)\n","        predicted = torch.round(outputs)\n","        predlist += predicted.cpu().detach().numpy().tolist()\n","        outputs = torch.sigmoid(outputs)\n","        y_test_preds += outputs.cpu().detach().numpy().tolist()\n","        y_test_trues += labels.cpu().detach().numpy().tolist()\n","auc_roc_score = roc_auc_score(y_test_trues, y_test_preds)\n","fpr, tpr, _ = roc_curve(y_test_trues, y_test_preds)\n","plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % auc_roc_score)\n","plt.plot([0, 1], [0, 1], 'k--')\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Receiver Operating Characteristic')\n","plt.legend(loc=\"lower right\")\n","plt.show()\n","confusion_mat = confusion_matrix(y_test_trues, predlist)\n","labels = ['Negative', 'Positive']\n","plt.figure(figsize=(5,5))\n","sns.heatmap(confusion_mat, xticklabels=labels, yticklabels=labels, annot=True, fmt='d', cmap='Blues')\n","plt.title('Confusion Matrix')\n","plt.xlabel('Predicted Label')\n","plt.ylabel('True Label')\n","plt.show()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":4}
